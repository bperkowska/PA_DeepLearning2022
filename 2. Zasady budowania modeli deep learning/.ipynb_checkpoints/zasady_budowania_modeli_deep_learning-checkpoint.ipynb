{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zasady budowania modeli deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dlaczego Julia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W trakcie kursu pracować będziemy w języku [Julia](https://julialang.org/). Dlaczego?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Język skryptowy (jak Python  czy R)\n",
    "- Szybkość  (jak C)\n",
    "- Silny  system [typów](https://upload.wikimedia.org/wikipedia/commons/d/d9/Julia-number-type-hierarchy.svg) \n",
    "- Wbudowane  zrównoleglanie  obliczeń\n",
    "- Łatwość  integracji  z innymi językami (Python, R, C, …) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literatura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przydatne linki:\n",
    "- [Kursy Julia Academy](https://juliaacademy.com/) - tu nie tylko kursy do Julii, ale także do datascience, ML and so on\n",
    "- [Podręcznik Boyda i Vandenberghe](http://vmls-book.stanford.edu/)\n",
    "- [Julia Express](https://github.com/bkamins/The-Julia-Express)\n",
    "- [wykłady Quantitative Economics Sargenta i Stachurskiego](https://lectures.quantecon.org/jl/)\n",
    "- [Julia dla Data Science](http://ucidatascienceinitiative.github.io/IntroToJulia/)\n",
    "- [Think Julia](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html)\n",
    "- [materiały dostępne na stronie języka](https://julialang.org/learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. DataFrames.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteka [<tt>DataFrames</tt>](https://dataframes.juliadata.org/stable/) jest narzędziem pozwalającym na efektywną i wygodną pracę ze zbiorami danych. Jest implementacja znanych z <tt>R</tt> ramek danych, oferując wszystkie znane z <tt>R</tt> narzędzia, zaimplementowane w wyraźnie efektywniejszy obliczeniowo sposób. Warto zapoznać się ze szczegółowym [wprowadzeniem do <tt>DataFrames</tt> ](https://github.com/bkamins/Julia-DataFrames-Tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plots.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Plots](https://docs.juliaplots.org/latest/tutorial/) to podstawowa bibliotka do tworzenia wykresów w Julii. Jedną z jej głównych zalet jest to, że pozwala na wykorzystanie wielu [backendów](http://docs.juliaplots.org/latest/backends/). Warto zapoznać się z [dokumenacją](http://docs.juliaplots.org/latest/) tej biblioteki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykład motywacyjny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane nie mają etykiet, chcemy odróżnić dobrych klientów (tych co spłacą) od złych (co nie spłacą); będziemy tu budować najprostszy perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od prostego przykładu. Dla australijskich danych dotyczących wniosków o karty kredytowe (dostepnych [tutaj](http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat)) zbudujmy model orkreślający prawdopodobieństwo decyzji o odmowie wydania karty kredytowej. Zacznijmy od odpowiedniedgo przygotowania danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles    # to read the file\n",
    "using PyPlot        # jest to jeden z backendów, który wchodzi w skład biblioteki Plots\n",
    "using Statistics    # for the count map\n",
    "using StatsBase     # for basic statistic functions\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "australian.dat zbiór danych australijskie dane kredytowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not isfile(....) then downolad(...)\n",
    "isfile(\"australian.dat\") ||\n",
    "download(\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat\",\n",
    "         \"australian.dat\" )\n",
    " \n",
    "# equivalently:\n",
    "if !isfile(\"australian.dat\")\n",
    "        download(\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat\",\"australian.dat\")\n",
    "end\n",
    "\n",
    "rawdata = readdlm(\"australian.dat\");\n",
    "# rawdata = readdlm(\"australian.dat\")    # it would display the output written this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14"
     ]
    }
   ],
   "source": [
    "# if condition\n",
    "3<1 && print(12)\n",
    "\n",
    "# if !condition\n",
    "3<1 || print(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×15 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">x1</th><th style = \"text-align: left;\">x2</th><th style = \"text-align: left;\">x3</th><th style = \"text-align: left;\">x4</th><th style = \"text-align: left;\">x5</th><th style = \"text-align: left;\">x6</th><th style = \"text-align: left;\">x7</th><th style = \"text-align: left;\">x8</th><th style = \"text-align: left;\">x9</th><th style = \"text-align: left;\">x10</th><th style = \"text-align: left;\">x11</th><th style = \"text-align: left;\">x12</th><th style = \"text-align: left;\">x13</th><th style = \"text-align: left;\">x14</th><th style = \"text-align: left;\">x15</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">22.08</td><td style = \"text-align: right;\">11.46</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.585</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">100.0</td><td style = \"text-align: right;\">1213.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">22.67</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.165</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">160.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">29.58</td><td style = \"text-align: right;\">1.75</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.25</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">280.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">21.67</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">20.17</td><td style = \"text-align: right;\">8.17</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.96</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">14.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">60.0</td><td style = \"text-align: right;\">159.0</td><td style = \"text-align: right;\">1.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 22.08 & 11.46 & 2.0 & 4.0 & 4.0 & 1.585 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 22.67 & 7.0 & 2.0 & 8.0 & 4.0 & 0.165 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 29.58 & 1.75 & 1.0 & 4.0 & 4.0 & 1.25 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 21.67 & 11.5 & 1.0 & 5.0 & 3.0 & 0.0 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 20.17 & 8.17 & 2.0 & 6.0 & 4.0 & 1.96 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×15 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1      \u001b[0m\u001b[1m x2      \u001b[0m\u001b[1m x3      \u001b[0m\u001b[1m x4      \u001b[0m\u001b[1m x5      \u001b[0m\u001b[1m x6      \u001b[0m\u001b[1m x7      \u001b[0m\u001b[1m x8      \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1.0    22.08    11.46      2.0      4.0      4.0    1.585      0.0  ⋯\n",
       "   2 │     0.0    22.67     7.0       2.0      8.0      4.0    0.165      0.0\n",
       "   3 │     0.0    29.58     1.75      1.0      4.0      4.0    1.25       0.0\n",
       "   4 │     0.0    21.67    11.5       1.0      5.0      3.0    0.0        1.0\n",
       "   5 │     1.0    20.17     8.17      2.0      6.0      4.0    1.96       1.0  ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrames.DataFrame(rawdata,:auto)\n",
    "first(df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×15 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">x1</th><th style = \"text-align: left;\">x2</th><th style = \"text-align: left;\">x3</th><th style = \"text-align: left;\">x4</th><th style = \"text-align: left;\">x5</th><th style = \"text-align: left;\">x6</th><th style = \"text-align: left;\">x7</th><th style = \"text-align: left;\">x8</th><th style = \"text-align: left;\">x9</th><th style = \"text-align: left;\">x10</th><th style = \"text-align: left;\">x11</th><th style = \"text-align: left;\">x12</th><th style = \"text-align: left;\">x13</th><th style = \"text-align: left;\">x14</th><th style = \"text-align: left;\">class</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">22.08</td><td style = \"text-align: right;\">11.46</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.585</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">100.0</td><td style = \"text-align: right;\">7.10085</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">22.67</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.165</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">160.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">29.58</td><td style = \"text-align: right;\">1.75</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.25</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">280.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">21.67</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">20.17</td><td style = \"text-align: right;\">8.17</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1.96</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">14.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">60.0</td><td style = \"text-align: right;\">5.0689</td><td style = \"text-align: right;\">1.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 22.08 & 11.46 & 0.0 & 4.0 & 4.0 & 1.585 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 22.67 & 7.0 & 0.0 & 8.0 & 4.0 & 0.165 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 29.58 & 1.75 & 1.0 & 4.0 & 4.0 & 1.25 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 21.67 & 11.5 & 1.0 & 5.0 & 3.0 & 0.0 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 20.17 & 8.17 & 0.0 & 6.0 & 4.0 & 1.96 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×15 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1      \u001b[0m\u001b[1m x2      \u001b[0m\u001b[1m x3      \u001b[0m\u001b[1m x4      \u001b[0m\u001b[1m x5      \u001b[0m\u001b[1m x6      \u001b[0m\u001b[1m x7      \u001b[0m\u001b[1m x8      \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1.0    22.08    11.46      0.0      4.0      4.0    1.585      0.0  ⋯\n",
       "   2 │     0.0    22.67     7.0       0.0      8.0      4.0    0.165      0.0\n",
       "   3 │     0.0    29.58     1.75      1.0      4.0      4.0    1.25       0.0\n",
       "   4 │     0.0    21.67    11.5       1.0      5.0      3.0    0.0        1.0\n",
       "   5 │     1.0    20.17     8.17      0.0      6.0      4.0    1.96       1.0  ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colon before the name of the column is just the syntax for the name of that column, like writing it in \"\"\n",
    "\n",
    "rename!(df,:x15 => :class) # changing last column's name\n",
    "\n",
    "# IF-ELSE CONDITION: if x==1 then it stays 1 if not it equals 0\n",
    "df[!,:x4] = [x == 1 ? 1.0 : 0.0 for x in df[!,:x4]]     \n",
    "df[!,:x12] = [x == 1 ? 1.0 : 0.0 for x in df[!,:x12]]\n",
    "\n",
    "# transforming for the logarithmic scale\n",
    "df[!,:x14] = log.(df[!,:x14])   \n",
    "\n",
    "first(df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column is a vector holding valuesof specific type - Julia chooses the best type working for all the data kept in that vector when reading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclamation mark (!) in above functions allows for modifications - cause it opens data in array instead of in a view mode\n",
    "df[!,:x4] \n",
    "\n",
    "# ale wychodzi mi na to, że taki syntax też:\n",
    "df[:,:x4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot vectorizes the code (will work on each element of an array), basically what it does above is writing such loop:\n",
    "\n",
    "for i in df[!,:x14]\n",
    "    log(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.328514   0.295467   1.72653\n",
       "  1.18637   -0.474888  -0.178598\n",
       " -1.28338   -1.69851   -0.619889"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(3,3); B = randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.311751  -1.21096   1.1257\n",
       " -0.395894  -1.28527  -0.43069\n",
       " -1.2475    -1.0028    1.21127"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B # multiplication of matrices (like in maths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.318945    0.217783   1.16672\n",
       "  0.0296081  -0.181024  -0.116887\n",
       " -1.25065    -0.052648  -0.465693"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.*B # multiplies just corresponding elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i = 1:4\n",
    "    println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i # in Python it would equal 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 4\n",
       " 6\n",
       " 8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list comprehensions as in Python (most efficient ways to avoid using for loops there; in Julia efficiency is the same as in loops, cause loops in Julia work well, but it improves code readability)\n",
    "\n",
    "a = [1,2,3,4]\n",
    "[2i for i in a]     # we can ommit * sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia jest językiem kompilowalnym, przez co zazwyczaj szybciej działa kiedy robimy operacje na danych tego samego typu (możemy je tworzyć na danych różnych typów, ale zazwyczaj wydłuża to czas kompilacji); <br>W Pythonie nie ma to znaczenia, nie wpływa na szybkość (zawsze będzie tak samo szybko) - bo jest językiem interpretowalnym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>15×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">x1</td><td style = \"text-align: right;\">0.678261</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">x2</td><td style = \"text-align: right;\">31.5682</td><td style = \"text-align: right;\">13.75</td><td style = \"text-align: right;\">28.625</td><td style = \"text-align: right;\">80.25</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">x3</td><td style = \"text-align: right;\">4.75872</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2.75</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">x4</td><td style = \"text-align: right;\">0.236232</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">x5</td><td style = \"text-align: right;\">7.37246</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">14.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">x6</td><td style = \"text-align: right;\">4.69275</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">x7</td><td style = \"text-align: right;\">2.22341</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">28.5</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">x8</td><td style = \"text-align: right;\">0.523188</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">x9</td><td style = \"text-align: right;\">0.427536</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">x10</td><td style = \"text-align: right;\">2.4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">67.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">x11</td><td style = \"text-align: right;\">0.457971</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">x12</td><td style = \"text-align: right;\">0.0826087</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">x13</td><td style = \"text-align: right;\">184.014</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">160.0</td><td style = \"text-align: right;\">2000.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">x14</td><td style = \"text-align: right;\">2.97232</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.79176</td><td style = \"text-align: right;\">11.5129</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">class</td><td style = \"text-align: right;\">0.444928</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Float64 & Float64 & Float64 & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & x1 & 0.678261 & 0.0 & 1.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t2 & x2 & 31.5682 & 13.75 & 28.625 & 80.25 & 0 & Float64 \\\\\n",
       "\t3 & x3 & 4.75872 & 0.0 & 2.75 & 28.0 & 0 & Float64 \\\\\n",
       "\t4 & x4 & 0.236232 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t5 & x5 & 7.37246 & 1.0 & 8.0 & 14.0 & 0 & Float64 \\\\\n",
       "\t6 & x6 & 4.69275 & 1.0 & 4.0 & 9.0 & 0 & Float64 \\\\\n",
       "\t7 & x7 & 2.22341 & 0.0 & 1.0 & 28.5 & 0 & Float64 \\\\\n",
       "\t8 & x8 & 0.523188 & 0.0 & 1.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t9 & x9 & 0.427536 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t10 & x10 & 2.4 & 0.0 & 0.0 & 67.0 & 0 & Float64 \\\\\n",
       "\t11 & x11 & 0.457971 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t12 & x12 & 0.0826087 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t13 & x13 & 184.014 & 0.0 & 160.0 & 2000.0 & 0 & Float64 \\\\\n",
       "\t14 & x14 & 2.97232 & 0.0 & 1.79176 & 11.5129 & 0 & Float64 \\\\\n",
       "\t15 & class & 0.444928 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m15×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean        \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median    \u001b[0m\u001b[1m max       \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype \u001b[0m ⋯\n",
       "     │\u001b[90m Symbol   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataTyp\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ x1          0.678261      0.0     1.0         1.0            0  Float64 ⋯\n",
       "   2 │ x2         31.5682       13.75   28.625      80.25           0  Float64\n",
       "   3 │ x3          4.75872       0.0     2.75       28.0            0  Float64\n",
       "   4 │ x4          0.236232      0.0     0.0         1.0            0  Float64\n",
       "   5 │ x5          7.37246       1.0     8.0        14.0            0  Float64 ⋯\n",
       "   6 │ x6          4.69275       1.0     4.0         9.0            0  Float64\n",
       "   7 │ x7          2.22341       0.0     1.0        28.5            0  Float64\n",
       "   8 │ x8          0.523188      0.0     1.0         1.0            0  Float64\n",
       "   9 │ x9          0.427536      0.0     0.0         1.0            0  Float64 ⋯\n",
       "  10 │ x10         2.4           0.0     0.0        67.0            0  Float64\n",
       "  11 │ x11         0.457971      0.0     0.0         1.0            0  Float64\n",
       "  12 │ x12         0.0826087     0.0     0.0         1.0            0  Float64\n",
       "  13 │ x13       184.014         0.0   160.0      2000.0            0  Float64 ⋯\n",
       "  14 │ x14         2.97232       0.0     1.79176    11.5129         0  Float64\n",
       "  15 │ class       0.444928      0.0     0.0         1.0            0  Float64\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Float64, Int64} with 2 entries:\n",
       "  0.0 => 383\n",
       "  1.0 => 307"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows how many elements we've got in each category (class column)\n",
    "countmap(df[!, :class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Float64, Int64} with 2 entries:\n",
       "  0.0 => 383\n",
       "  1.0 => 307"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works also this way: \n",
    "countmap(df[!, \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df,1) #number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df,2)  # number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing into train and test set (just by cutting the dataset, no random choosing; we ommited this step to simplify the code and cause our data in our dataset is already shuffeled)\n",
    "\n",
    "train_ratio = 0.7\n",
    "train_set = df[1:floor(Int,size(df,1)*train_ratio),:];\n",
    "test_set = df[floor(Int,size(df,1)*train_ratio + 1):end,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: first two are transposed, so it is correct from mathematical point of view\n",
    "\n",
    "X_train = Matrix(train_set[:,1:end-1])';        # without class column!\n",
    "X_test = Matrix(test_set[:,1:end-1])';\n",
    "y_train = train_set[!, :class];                 # only class column\n",
    "y_test = test_set[!, :class];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482×14 Matrix{Float64}:\n",
       " 1.0  22.08  11.46   0.0   4.0  4.0  …   0.0  1.0  0.0  100.0  7.10085\n",
       " 0.0  22.67   7.0    0.0   8.0  4.0      0.0  0.0  0.0  160.0  0.0\n",
       " 0.0  29.58   1.75   1.0   4.0  4.0      0.0  1.0  0.0  280.0  0.0\n",
       " 0.0  21.67  11.5    1.0   5.0  3.0     11.0  1.0  0.0    0.0  0.0\n",
       " 1.0  20.17   8.17   0.0   6.0  4.0     14.0  0.0  0.0   60.0  5.0689\n",
       " 0.0  15.83   0.585  0.0   8.0  8.0  …   2.0  0.0  0.0  100.0  0.0\n",
       " 1.0  17.42   6.5    0.0   3.0  4.0      0.0  0.0  0.0   60.0  4.61512\n",
       " 0.0  58.67   4.46   0.0  11.0  8.0      6.0  0.0  0.0   43.0  6.32972\n",
       " 1.0  27.83   1.0    1.0   2.0  8.0      0.0  0.0  0.0  176.0  6.28786\n",
       " 0.0  55.75   7.08   0.0   4.0  8.0      3.0  1.0  0.0  100.0  3.93183\n",
       " 1.0  33.5    1.75   0.0  14.0  8.0  …   4.0  1.0  0.0  253.0  6.7546\n",
       " 1.0  41.42   5.0    0.0  11.0  8.0      6.0  1.0  0.0  470.0  0.0\n",
       " 1.0  20.67   1.25   1.0   8.0  8.0      3.0  1.0  0.0  140.0  5.35186\n",
       " ⋮                              ⋮    ⋱        ⋮                \n",
       " 1.0  20.17   9.25   0.0   8.0  4.0  …   3.0  1.0  0.0   40.0  3.3673\n",
       " 1.0  48.17   7.625  0.0   9.0  8.0     12.0  0.0  0.0    0.0  6.6733\n",
       " 1.0  23.25   1.5    0.0  11.0  4.0      3.0  1.0  0.0    0.0  6.36819\n",
       " 1.0  32.25  14.0    1.0   1.0  1.0      2.0  0.0  0.0  160.0  0.693147\n",
       " 1.0  33.58   0.335  1.0  13.0  4.0      0.0  0.0  0.0  180.0  0.0\n",
       " 1.0  23.58   0.46   1.0   9.0  4.0  …   6.0  1.0  0.0  208.0  5.8522\n",
       " 1.0  16.92   0.335  1.0   4.0  4.0      0.0  0.0  1.0  200.0  0.0\n",
       " 0.0  20.83   8.5    0.0   8.0  4.0      0.0  0.0  0.0    0.0  5.86363\n",
       " 0.0  60.58  16.5    0.0  11.0  4.0      0.0  1.0  0.0   21.0  9.26502\n",
       " 1.0  31.57   5.0    1.0   6.0  4.0      0.0  0.0  0.0    0.0  0.0\n",
       " 0.0  25.0   12.33   0.0  13.0  8.0  …   6.0  0.0  0.0  400.0  6.12905\n",
       " 1.0  21.5    9.75   0.0   8.0  4.0      0.0  0.0  0.0  140.0  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train';    # creates adjoint, new object (generalized version of transposizion operation; works also for complex numbers)\n",
    "# or (slight difference between them)\n",
    "transpose(X_train);  # view of a transposed matrix, does not create a new object (it is a reference only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metody w Pythonie są połączone z obiektami, nie są globalnymi funkcjami jak w Julii\n",
    "<br>W Julii - metody to funkcje, które mają to samo imię, ale robią różne rzeczy; w szczególności dla różnych typów danych mogą nawet robić to samo ale być zoptymalizowane pod ten typ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znormalizujmy zmienne (możnaby to zrobić wcześniej na całym zbiorze; byłoby mniej kodu w sumie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function scale(X::Array{Float64,2}) #if we wrote sth like this syntax - here we forse the function to use a specific type of data; here, matrix with only floats64 in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scale (generic function with 2 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scale(X) #   here we forse the function to use a specific type of data; here, matrix with only floats64 in it\n",
    "\n",
    "    μ = mean(X, dims=2)\n",
    "    σ = std(X, dims=2)\n",
    "\n",
    "    X_norm = (X .- μ) ./ σ\n",
    "\n",
    "    return (X_norm, μ, σ);\n",
    "end\n",
    "\n",
    "# we create second function that willallow us to use parameters from X_train to normalize X_test\n",
    "function scale(X, μ, σ)\n",
    "    X_norm = (X .- μ) ./ σ\n",
    "    return X_norm;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, μ, σ = scale(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scale(X_test, μ, σ);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I zdefiniujmy funkcję szacującą regresję logistyczną, którą chcemy wyliczyć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_train,1) # we add 1 later to include the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = rand(1,size(X_train,1) + 1);    # returns random values from the uniform distribution from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×15 Matrix{Float64}:\n",
       " 0.325929  0.821755  0.291455  0.96576  …  0.141513  0.137685  0.688141"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β   # we want betas to be from the [-1, 1] interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -β[1:end-1]' * x .- β[end] # this is our linear combination (we don't have 1 in data for the intercept, that's why it's added later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predict (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we generate logistic regression function (sigmoid function)\n",
    "# function predicts value of a logistic regression function for any (or each, cause it's vectorized) observation\n",
    "# x is a vector containing values of all variables for each observation\n",
    "\n",
    "Predict(β, x) = 1 ./ (1 .+ exp.(-β[1:end-1]' * x .- β[end]))\n",
    "\n",
    "# thanks to . operator we can later use this function for all elements of the dataset at one call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moje kminy:\n",
    "<br>\n",
    "Czyli sieć zwraca predykcję dla jednej obserwacji; bo jedna obserwacja to wektor zmiennych <b>x </b>;I tą samą sieć stosujemy na wszystkich obserwacjach \n",
    "<br>\n",
    "I guess że funkcja nam zwraca wartość y przewidywaną, ponieważ to jest perceptron (ma tylko jeden neuron i z niego wychodzi ostateczny wynik) - ale robi to dla konkretnej obserwacji za jednym wywołaniem, nie dla całego datasetu naraz!; \n",
    "<br>i później na podstawie tej wartości(którą możemy interpretować jako prawdopodobieństwo, (fukcja logistyczna przyjmuje wartości z zakresu [0,1]) będziemy klasyfikować przynależność do danej klasy ... próg odcięcia 0.5 (pytanie: czy mozna inny?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Matrix{Float64}:\n",
       " 0.566281  0.206271  0.0345944  0.963201  0.658031  0.947975"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β,X_train[:,5:10])  # wcześniej była zamiana miejsc kolumn z wierszami; więc teraz w kolumnach mamy obserwacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Vector{Float64}:\n",
       "  0.6943159862747523\n",
       " -0.7947550351313383\n",
       "  1.3293163801491459\n",
       " -0.5368155600214782\n",
       " -0.9069402649279451\n",
       " -0.3497944253550831\n",
       " -0.20449259729312871\n",
       " -1.0413096422523735\n",
       " -0.9077689054855181\n",
       " -0.49461786246815215\n",
       "  1.0500054142809863\n",
       " -0.2663898978669589\n",
       " -0.4697726623866166\n",
       "  1.2943449493042467"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2589654064860467"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β,X_train[:,1]) # funkcja wzięła wszystkie wartości zmiennych dla pierwszej obserwacji i zrobiła kombinację liniową z wektorem bet, wrzuciła to do funkcji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×482 Matrix{Float64}:\n",
       " 0.258965  0.0649042  0.571826  0.879275  …  0.892397  0.905183  0.248167"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β,X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczynamy proces uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mierzymy się z problemem klasyfikacji, dlatego jako funkcję straty wykorzystamy binarną entropię krzyżową <b> binary cross-entropy </b>, (która w przypadku regresjii logistycznej z dwoma kategoriami przekształca się w funkcję kosztu regresjii logistycznej <b>log-loss</b>). Jej wzór to:\n",
    "\n",
    "$$ H_p(q) = - \\sum_{i=1}^N {y_i log(p(y_i)) + (1 - y_i) log(p(1 -y_i))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrz podręcznik O'reilly (gruby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the actual class, ŷ is the predicted probability of being class 1\n",
    "L(ŷ, y) = (-y') * log.(ŷ') - (1 .- y') * log.(1 .- ŷ')                  # nie widać tego tu w zapisie, ale minusy dlatego że chcemy mieć funkcję -log(sth), nie log(sth)\n",
    "                                                                        # operator mnożenia nie jest zwektoryzowany, dlatego mamy iloczyn skalarny - will sum loss functions for the entire ŷ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×482 Matrix{Float64}:\n",
       " 0.258965  0.0649042  0.571826  0.879275  …  0.892397  0.905183  0.248167"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(β, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float64}:\n",
       " 0.2997079698716359"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(Predict(β, X_train[:,1]), y_train[1,:])   # value of loss function on the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float64}:\n",
       " 353.6383618430626"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(Predict(β, X_train),y_train)  # wychodzi na to że ona sumuje wszystkie loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482×482 Matrix{Float64}:\n",
       " 0.299708   0.299708   0.299708   …  0.299708   1.35106     0.299708\n",
       " 0.0671063  0.0671063  0.0671063     0.0671063  2.73484     0.0671063\n",
       " 0.848225   0.848225   0.848225      0.848225   0.558921    0.848225\n",
       " 2.11424    2.11424    2.11424       2.11424    0.128657    2.11424\n",
       " 0.835359   0.835359   0.835359      0.835359   0.568664    0.835359\n",
       " 0.231013   0.231013   0.231013   …  0.231013   1.57856     0.231013\n",
       " 0.0352069  0.0352069  0.0352069     0.0352069  3.36406     0.0352069\n",
       " 3.30228    3.30228    3.30228       3.30228    0.0374932   3.30228\n",
       " 1.07304    1.07304    1.07304       1.07304    0.418503    1.07304\n",
       " 2.95603    2.95603    2.95603       2.95603    0.0534271   2.95603\n",
       " 4.07975    4.07975    4.07975    …  4.07975    0.0170564   4.07975\n",
       " 4.30403    4.30403    4.30403       4.30403    0.0136061   4.30403\n",
       " 3.54339    3.54339    3.54339       3.54339    0.0293413   3.54339\n",
       " ⋮                                ⋱             ⋮           \n",
       " 0.989223   0.989223   0.989223   …  0.989223   0.465001    0.989223\n",
       " 5.28501    5.28501    5.28501       5.28501    0.00507984  5.28501\n",
       " 1.40554    1.40554    1.40554       1.40554    0.281349    1.40554\n",
       " 0.430724   0.430724   0.430724      0.430724   1.04993     0.430724\n",
       " 1.93317    1.93317    1.93317       1.93317    0.156291    1.93317\n",
       " 3.50559    3.50559    3.50559    …  3.50559    0.0304891   3.50559\n",
       " 1.66493    1.66493    1.66493       1.66493    0.209738    1.66493\n",
       " 0.0734938  0.0734938  0.0734938     0.0734938  2.64708     0.0734938\n",
       " 4.68327    4.68327    4.68327       4.68327    0.00929173  4.68327\n",
       " 2.22931    2.22931    2.22931       2.22931    0.113844    2.22931\n",
       " 2.3558     2.3558     2.3558     …  2.3558     0.0996183   2.3558\n",
       " 0.285241   0.285241   0.285241      0.285241   1.39365     0.285241"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tu jakiś eksperyment robię\n",
    "LL(ŷ, y) = (-y') .* log.(ŷ') - (1 .- y') .* log.(1 .- ŷ') \n",
    "LL(Predict(β, X_train),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×15 LinearIndices{2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}:\n",
       " 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearIndices(β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×15 BitMatrix:\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(LinearIndices(β) .== 2)    # false/true values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×15 Matrix{Float64}:\n",
       " 0.0  1.22451e-8  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(LinearIndices(β) .== 2) * β[2] * √eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps()   #  (in different languages we may have slightly diffferent machine epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps() ^-45  # that's why we use gradient descent not analytical formula for the derivative -computers cannot represent sth so close to 0, and differentiation by definition comes with that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do rozwiązania zadanego problemu wykorzystamy [metodę gradientu prostego](https://pl.wikipedia.org/wiki/Metoda_gradientu_prostego). Zdefiniujmy funkcję, która wyznacza gradient w pojedynczej iteracji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_∇ (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simple_∇(β, X, y)      # β - W; X - variables values (all observations), y- our target (estimated class or actual class)\n",
    "    \n",
    "    J = L(Predict(β, X),y)[1]   # calculating cost function for all the predictions (for current β vector); [1] cause L returns 1x1 matrix\n",
    "    ∇ = Float64[]               # we create empty vector for new derivatives of cost function\n",
    "\n",
    "    # calculating derivatives\n",
    "    for i = 1:length(β)         \n",
    "        b = β[i]\n",
    "        β′ = β .+ (LinearIndices(β) .== i) * b * √eps()                             # FOR THE CENTRAL NUMERICAL DERIVATIVE: here we add/subtract some small value (depending on b sign)\n",
    "        β′′ = β .- (LinearIndices(β) .== i) * b * √eps()                            # here we do the opposite with the same value\n",
    "        Δf = (L(Predict(β′,X),y)[1] - L(Predict(β′′,X),y)[1]) / (2*b*√eps())        # here we apply derivative formula (it's numericaly adjusted so it will work)\n",
    "        push!(∇,Δf)                                                                 # we push all derivatives into a gradient\n",
    "    end\n",
    "\n",
    "    return J, ∇\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353.6383618430626, [32.66592564213328, 27.23341776631074, -5.610914452646812, 84.94451408600325, -19.658499078698252, 8.95318808790129, -1.000081780072722, -83.63972218609123, -71.77655701172982, -40.225023766058456, 54.30599812413071, 60.07131148853533, 39.65962022417525, -49.23380274467204, 61.82312625775555])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_∇(β,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dopiero tutaj robimy gradient descent method:\n",
    "<br> (ta funkcja ma bład w sobie! dlatego niskie accuracy, niżej poprawiona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve! (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ϵ, maxit are our termination criterions - we stop if one is fullfilled\n",
    "\n",
    "function solve!(β, X, y;\n",
    "            η = 0.001, ϵ = 10^-10, maxit = 50_000)\n",
    "    iter = 1\n",
    "    Js = Float64[]\n",
    "    J, ∇ = simple_∇(β, X, y)\n",
    "    push!(Js,J)\n",
    "    while true\n",
    "        β₀ = β  #1st source of error: we create a reference only\n",
    "        β -= η * ∇' #2nd source of error: \n",
    "        J, ∇ = simple_∇(β, X, y)\n",
    "        push!(Js,J)\n",
    "        stop = maximum(abs.(β .- β₀))\n",
    "        stop < ϵ && break\n",
    "        iter += 1\n",
    "        iter > maxit && break\n",
    "    end\n",
    "    return Js   # vector of the cost dunction\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = solve!(β,X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x000000004EB97A60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Js[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x0000000053C8A650>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.12799108308872\n",
      "156.12930242548833\n"
     ]
    }
   ],
   "source": [
    "println(Js[2000]); println(Js[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X, y, T = 0.5) = sum((Predict(β, X)' .≥ T ).== y)/length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6394230769230769"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu naprawiamy funkcję tak aby zwracała zaktualizowany wektor beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve! (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function solve!(β, X, y;\n",
    "            η = 0.001, ϵ = 10^-10, maxit = 50_000)\n",
    "    iter = 1\n",
    "    Js = Float64[]\n",
    "    J, ∇ = simple_∇(β, X, y)\n",
    "    push!(Js,J)\n",
    "    while true\n",
    "        β₀ = deepcopy(β)    # 1ST FIX: we create a deepcopy\n",
    "\n",
    "        # β -= η * ∇'       # this way function does not return updated right β, cause in Julia when you subtract 2 vectors it creates a new object;\n",
    "                            # so the previous object (on the left side of the equation) won't be updated; hence we need to vectorize it\n",
    "        β .-= η * ∇'        # 2ND FIX\n",
    "\n",
    "        J, ∇ = simple_∇(β, X, y)\n",
    "        push!(Js,J)\n",
    "        stop = maximum(abs.(β .- β₀))\n",
    "        stop < ϵ && break\n",
    "        iter += 1\n",
    "        iter > maxit && break\n",
    "    end\n",
    "    return Js   # vector of the cost dunction\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = solve!(β,X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x0000000053CFB2E0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Js[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{PyCall.PyObject}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x0000000053D63CA0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.12799108308872\n",
      "156.12930242548833\n"
     ]
    }
   ],
   "source": [
    "println(Js[2000]); println(Js[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X, y, T = 0.5) = sum((Predict(β, X)' .≥ T ).== y)/length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8798076923076923"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(β, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy dane są już gotowe kolejnym krokiem jest odpowiednie zdefiniowanie modelu na którym będziemy pracować. Wykorzystamy do tego bibliotekę [flux.jl](http://fluxml.ai/):\n",
    "\n",
    "- [Flux](http://fluxml.ai/) jest biblioteką Julii przeznaczoną do tworzenia modeli uczenia maszynowego (w całości napisanej w Julii).\n",
    "- Jest w całości oparta na Julii, przez co trywialne jest jej modyfikowanie i dostosowywanie do swoich potrzeb. \n",
    "- Możliwe jest przy tym wykorzystanie wewnątrz modeli składni, funkcji i makr Julii.\n",
    "- Przy czym tworzenie całkiem złożonych standardowych modeli jest intuicyjne i szybkie, zazwyczaj zajmują one jedynie kilka linijek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Pythonie większość bibliotek jest pisana w C, w Julii większość jest pisana w niej samej, co potem może okazać się kluczowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warstwy sieci neuronowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Jak już wspomnieliśmy wcześniej Flux jest wpełni modyfikowalny i możemy samodzielnie zdefiniować warstwy takiej sieci, korzystając np. z sigmoidalnej funkcją aktywacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux is flexible (Advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15.285264 seconds (18.88 M allocations: 1.204 GiB, 5.37% gc time, 19.91% compilation time: 53% of which was recompilation)\n"
     ]
    }
   ],
   "source": [
    "@time using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×8 Matrix{Float64}:\n",
       " 0.922193    0.633587  0.0982615   0.736122  …  0.565474   0.813186  0.46536\n",
       " 0.00818939  0.223323  0.592642    0.626892     0.0962596  0.251844  0.957105\n",
       " 0.192321    0.766278  0.625618    0.294304     0.555842   0.960392  0.891585\n",
       " 0.477012    0.70224   0.00618391  0.502477     0.769558   0.212328  0.695348"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(4, 8) # Weights; 4 neurons on the first hidden layer, 8 data points from the imput layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9818342337475212\n",
       " 0.056003225656721334\n",
       " 0.8842341275726199\n",
       " 0.4672407434140422"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = rand(4) # intercepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Float64}:\n",
       " 0.5939826756245027\n",
       " 0.27917396175689246\n",
       " 0.10273970759768047\n",
       " 0.0298920334394448\n",
       " 0.13936477147824222\n",
       " 0.14016683559618415\n",
       " 0.7849776275870136\n",
       " 0.42586431418255355"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(8) # our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 2.699569017529896\n",
       " 0.9030542721189696\n",
       " 2.6323239336148183\n",
       " 1.5882910267939492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W*x + b) # values after agreggations that will be put into logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer₁ (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₁(data) = 1.0 ./ (1.0.+exp.(-(W*x + b)))    # activation functionon the 1st layer a neural network: sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9370012078628092\n",
       " 0.7115767518616302\n",
       " 0.9329131420223769\n",
       " 0.830375526641191"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₁(x)   # output values (predicted y by the network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy czym w przypaku najpowszechniejszych funkcji nie musimy ich samodzielnie deklarować. Flux dostarcza  najpopularniejsze funkcje aktywacji i podstawowe typy [warstw modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Basic-Layers-1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(w razie co: może wywalić tu błąd bo wcześniej cos się namieszało w pamięci; wtedy zrestartować kernela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9370012078628092\n",
       " 0.7115767518616302\n",
       " 0.9329131420223769\n",
       " 0.830375526641191"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ.(W * x .+ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.9370012078628092\n",
       " 0.7115767518616302\n",
       " 0.9329131420223769\n",
       " 0.830375526641191"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer₂(x) = σ.(W * x .+ b) # other way of defining layer same as above, with sigmoid function\n",
    "layer₂(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.5001266494228814\n",
       " 0.5823468703320588\n",
       " 0.4950891365629633\n",
       " 0.4320429102836754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Dense function from Flux\n",
    "# ona chyba losuje własne \n",
    "\n",
    "layer₃ = Dense(8,4,σ) # 8 data points are inserted to this layer, 4 neurons that apply sigmoid activation function on aggregated data (W * x .+ b) - 4 data points leave the layer\n",
    "layer₃(x)             # za każdym razem printuje inne wartości; a więc pewnie losuje W, V i b?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować też własne warstwy jako obiekty ( w Julli obiekt jest kontenerem na dane, nie da się w nim definiować metod w środku stuktury, ale możemy definiować funkcję o tym samym imieniu dla obiekótw tej struktury (overload call poniżej)):\n",
    "<br> Uwaga: komórkę poniżej akurat rozkminiałam ten kod trochę sama, więc nie wiem czy wszystko co napisałam ma sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1729040285750911, 1.095403140933128, -0.4907882968174772, -1.1043166978260666, 0.8158508006422721]"
     ]
    }
   ],
   "source": [
    "# Poly will be our layer with polynomial activation function\n",
    "struct Poly\n",
    "  W\n",
    "  V\n",
    "  b\n",
    "end\n",
    "\n",
    "# DEFINING CONSTRUCTOR FUNCTION with telling Julia how to generate attributes of an Poly object while creating it (W, V and b)...\n",
    "Poly(in::Integer, out::Integer) =\n",
    "  Poly((randn(out, in)),randn(out, in), (randn(out)))\n",
    "\n",
    "# here we generate object of a struct Poly - we can imput only 2 parameters, because of what we did above\n",
    "a = Poly(10, 5)\n",
    "\n",
    "# now we created an object a of a struct Poly\n",
    "print(a.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -0.8683440161882047\n",
       "  3.047189098216\n",
       "  0.37809364037637266\n",
       " -1.466704229220914\n",
       "  0.6149079155932095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overload call, so the object can be used as a function (sinilar to methods in function) - will work only for Poly objects\n",
    "(m::Poly)(x) = m.W * x.^2 + m.V*x .+ m.b\n",
    "\n",
    "a(rand(10)) # => 5-element vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notes \n",
    "\n",
    "object = Poly(2,3,4)\n",
    "object.V\n",
    "\n",
    "object3 = Poly(12,13,14)\n",
    "object3.V\n",
    "\n",
    "# # NOTE: this won't work:\n",
    "# object2 = Poly(randn(out, in),randn(out, in), randn(out))\n",
    "# object2.V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znów, samo zdefioniowanie warstwy jako obiektu nie wystarczy do wykorzystania wszystkich funkcji Fluxa. Gdy chcemy wykorzystać wbudowane we Fluxa narzędzia do wyznaczania gradientu czy też [liczyć model na GPU](https://fluxml.ai/Flux.jl/stable/gpu/)  musimy jeszcze skorzystać z makra <tt>@functor </tt> (czyli musimy napisać 2 komórki poniżej jeśli definiujemy warstwę sami):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@functor  Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux C:\\Users\\Berenika\\.julia\\packages\\Flux\\kq9Et\\src\\functor.jl:201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Poly([0.01776358987744461 -0.14307251678600874 … -0.752089008789377 0.5473328778117292; -0.2421327823893983 0.86479696948201 … 1.0849013069423297 -1.3102206300527897; … ; 1.391136884878661 -0.8868465888474296 … 1.1594552602661325 1.3301843070919184; -1.0073353900198128 0.14085872953442322 … -0.999870931988183 0.15692084640779874], [0.34767551559597726 0.28541595378932766 … -0.2782602172129696 1.6413075125696814; -1.0991566083393856 -1.3408005168849806 … 2.0730437454372295 0.38644066923875964; … ; -0.44471078942505193 -1.0538121687740387 … 1.5202544276730605 -0.5328744719114111; 0.816591044541774 1.1068329103027763 … -2.03450855906189 1.7733108558191775], [-1.1729040285750911, 1.095403140933128, -0.4907882968174772, -1.1043166978260666, 0.8158508006422721])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu(a)  # a, because we named it earlier so and we have only a; zawsze trzeba dla wszystkicg obiektów które nas interesują to zrobić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcąc zbudować model z więcej niż jedną warstwą musimy go odpowiednio zdefiniować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 3 methods)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer₁ = Dense(28^2, 32, relu)\n",
    "Layer₂ = Dense(32, 10)  # chyba defaultowo mamy funkcję  aktywacji identity\n",
    "Layer₃ = softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja <tt>Chain</tt> pozwala łączyć w łancuchy dowolne funkcje w Julii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(#3, #4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = Chain(x -> x^2, x-> -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(#7, #8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = Chain(x -> x.^2, x-> .-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       "  -4\n",
       "  -9\n",
       " -25\n",
       "  -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 32, relu),               \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m25_450 parameters, 99.664 KiB."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₁ = Chain(Layer₁ , Layer₂, Layer₃) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zdefiniować model także jako złożenie funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₂ (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₂(x) = Layer₃(Layer₂(Layer₁(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₃ (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₃(x) = Layer₁ ∘ Layer₂ ∘ Layer₃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albo jako potok (pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m₄ (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m₄(x) = Layer₁(x) |> Layer₂  |> Layer₃ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje kosztu i regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 7](http://www.deeplearningbook.org/contents/regularization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak mówiliśmy na poprzednim wykładzie nie mamy możliwości bezpośredniej optymalizacji wag $\\theta$ w modelu. Do procesu uczenia musimy wykorzystać funkcję kosztu $J(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcję straty możemy zdefiniować samodzielnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8291915899190543"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dense(5,2)\n",
    "x, y = rand(5), rand(2);\n",
    "loss(ŷ, y) = sum((ŷ.- y).^2)/ length(y) # suma kwadratów roznic/ liczba estymowanych wartości (czyli dokładnie mse)\n",
    "loss(model(x), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo wykorzystać [jedną z zaimplementowanych we Fluxie](https://github.com/FluxML/Flux.jl/blob/8f73dc6e148eedd11463571a0a8215fd87e7e05b/src/layers/stateless.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8291915899190543"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here mean sqaure error \n",
    "Flux.mse(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednak samo zdefiniowanie funkcji straty nie wystarczy. Dobry model uczenia maszynowego musi mieć możliwie jak najniższy <b>błąd generalizacji</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://cdn-images-1.medium.com/max/1600/1*1woqrqfRwmS1xXYHKPMUDw.png)](https://buzzrobot.com/bias-and-variance-11d8e1fee627)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety sieci neuronowe mają tendencję do przeuczania się i w przypadku ich używania konieczne jest wykorzystanie odpowiedniej metody <b>regularyzacji</b>. Dzięki temu możliwe będzie zaproponowanie modelu, który będzie umiał efektywnie aproksymować dane inne niż trenujące.\n",
    "\n",
    "Do najczęściej wykorzystywanych metod regularyzacji należą:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>nakładanie kar na parametry</b>:\n",
    "\n",
    "Jeden z najczęściej wykorzystywanych sposobów regularyzacji. Polega on na nałożeniu unormowanej kary na parametry funkcji straty:\n",
    "\n",
    "$\\tilde{J}(\\theta) = J(\\theta) + \\alpha\\Omega(\\theta)$\n",
    "\n",
    "Najczęściej spotykamy się z postaciami:\n",
    "- $\\Omega(\\theta) = ||\\theta||_1 = \\sum_i{|\\theta_i|}$     (<i>LASSO</i>,<i>regularyzacja $L_1$</i>)\n",
    "- $\\Omega(\\theta) = ||\\theta||_2^2 = \\sum_i{\\theta_i^2}$ (<i>regularyzacja Tichonowa</i>, <i>regresja grzbietowa</i>,<i>regularyzacja $L_2$</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich implementacja wyglądałaby [następująco](https://fluxml.ai/Flux.jl/stable/models/regularisation/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L₂ (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L₁(θ) = sum(abs, θ) \n",
    "L₂(θ) = sum(abs2, θ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(x,y,W) = loss(model(x),y) + L₁(W) #new cost function with LASSO regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.748309945902797"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J(x,y,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy też inne metody regularyzacji:\n",
    "<br><b>Bagging (bootstrap aggregating)</b>(przydatny gdy mamy za mało danych) (not a good idea for neural networks; computations would last forever):\n",
    "\n",
    "Polega on na losowaniu ze zwracaniem $k$ próbek z wejściowego zbioru danych i szacowaniu na nich $k$  modeli, a następnie uśrednianiu ich rezultatów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or instead of bagging: <b>Dropout</b>:\n",
    "\n",
    "Polega na tworzeniu nowych modeli poprzez usuwanie neuronów z warstw ukrytych z prawdopodobieństwem $p$ w każdej iteracji uczenia. Niech wektor $\\mu = [1,1,0,1,1,1,\\dots,0,1]$ oznacza neurony wykorzystane do uczenia modelu w danej iteracji $i$. W takim wypadku procedura uczenia sprowadza się do minimalizacji wartości wyrażenia $E_\\mu[J(\\theta,\\mu)]$ dla każdej kolejnej iteracji. Dzięki temu otrzymujemy nieobciążony estymator gradientu bez konieczności generowania i uczenia $k$ modeli tak jak w przypadku baggingu.\n",
    "\n",
    "Dropout implementuje się we Fluxie jako [warstwę modelu](https://fluxml.ai/Flux.jl/stable/models/layers/#Normalisation-and-Regularisation-1): \n",
    "<br> (W innnych środowiskach często jest implementowana globalnie, wtedy usuwa neurony ze wszystkich warstw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 32, relu),               \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dropout(0.1),\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  BatchNorm(64, relu),                  \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 6 trainable arrays, \u001b[39m25_578 parameters,\n",
       "\u001b[90m          # plus 2 non-trainable, 128 parameters, summarysize \u001b[39m100.922 KiB."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(28^2, 32, relu),\n",
    "    Dropout(0.1), # removes neurons only from the NEXT layer (the one below): Dense(32, 10)\n",
    "Dense(32, 10),\n",
    "BatchNorm(64, relu),\n",
    "softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Goodfellow I., Bengio Y., Courville A. (2016), Deep Learning, rozdział 8](http://www.deeplearningbook.org/contents/optimization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobór odpowiedniego algorytmu optymalizacyjnego jest jednym z najważniejszych kroków w trakcie przygotowywania sieci neuronowej. Specyfika procesu ich uczenia powoduje, że proces optymalizacji jest podatny na wiele potencjalnych problemów, między innymi:\n",
    "- złe uwarunkowanie macierzy.\n",
    "- występowanie lokalnych minimów, punktów siodłowych, etc.\n",
    "- zjawiska zanikającego i eksplodującego gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z tego powodu istnieje wiele różnych algorytmów, które próbują przeciwdziałać wymienionym powyżej problemom. To który z nich powinien być zastosowany zależy tak naprawdę od specyfiki rozpatrywanego przypadku. Do najpopularnieszych należą:\n",
    "- SGD [(Robbins & Munro 1951)](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586)\n",
    "- SGD z pędem (momentum) [(Polyak, 1964)](http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=zvmmf&paperid=7713&option_lang=eng)\n",
    "- SGD z pędem Nesterova ([Nesterov, 1983](http://www.cis.pku.edu.cn/faculty/vision/zlin/1983-A%20Method%20of%20Solving%20a%20Convex%20Programming%20Problem%20with%20Convergence%20Rate%20O%28k%5E%28-2%29%29_Nesterov.pdf), [2005](https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf))\n",
    "- AdaGrad (Adaptive Gradient Algorithm) [(Duchi et. al. 2011)](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "- ADAM (Adaptive Moment Estimation) [(Kingma & Ba, 2015)](https://arxiv.org/abs/1412.6980)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z funkcjami straty jest ten problem, że często się wypłaszczają (dużo płaskowyży) i robią inne dziwne rzeczy (ich przebieg jest nietrywialny); szansa że wpadniemy do minimum globalnego jest niewielka; raczej wpadniemy do minimum lokalnego, musimy po prostu stwierdzić czy jest ono wystarczająco dobre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux umożliwia [wyznaczanie gradientu dowolnej funkcji](https://fluxml.ai/Flux.jl/stable/models/basics/) i przekazanie go do modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "\n",
    "# df/dx = 6x + 2\n",
    "df(x) = gradient(f, x)[1]   #[1] removes the tuple(takes only value from it)\n",
    "\n",
    "df(2) # 14.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d²f/dx² = 6\n",
    "d²f(x) = gradient(df, x)[1]\n",
    "\n",
    "d²f(2) # 6.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/> Dotąd spotkanie 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dotyczy to także dowolnych funkcji (nie tylko tych wyrażonych za pomocą metamatycznej formuły): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pow (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pow(x, n)\n",
    "    r = 1\n",
    "    for i = 1:n\n",
    "        r *= x\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(x -> pow(x, 3), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu się jeszcze przyjrzeć może i warto co tu się dzieje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pow2 (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow2(x, n) = n <= 0 ? 1 : x*pow2(x, n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(x -> pow2(x, 3), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzieje się tak dzięki odpowiednio skonstruowanemu mechanizmowi różniczkowania, który efektywnie wykorzystuje charakterystykę języka.  Biblioteka [<tt>Zygote.jl</tt>](https://fluxml.ai/Zygote.jl/latest/) służy do automatycznego różniczkowania w Julii. Wprowadzenie do sposobu jej działania dostępne jest [tutaj](https://github.com/MikeInnes/diff-zoo) i [tutaj](https://arxiv.org/pdf/1810.07951.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatyczne różniczkowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kluczowym elementem poprawnie działającej biblioteki do uczenia maszynowego jest odpowiedni algorytm wyznaczający gradient funkcji. Jak wiemy z poprzednich zajęć naiwne wyznaczanie gradientu za pomocą definicji pochodnej:\n",
    "$$\\frac{df}{dx} = \\lim_{h \\to 0}\\frac{f(x_0 +h) - f(x_0)}{h}$$\n",
    "nie jest efektywne numerycznie. W jaki sposób możemy wyznaczać wartości pochodnych?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że każda, nawet najbardziej skomplikowana funkcja, którą liczymy jest niczym innym niż złożeniem podstawowych operacji arytmetycznych i kilku bazowych funkcji (sin,cos,log,etc.).  Znając podstawowe reguły wyliczania tych pochodnych możemy w efektywny sposób wyznaczyć wartość pochodnej korzystając z reguły łańcuchowej:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy_1}{dx}*\\frac{dy_2}{dy_1}*\\dots*\\frac{dy_{n-1}}{dy_{n-2}}*\\frac{dy}{dy_{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różniczkowanie można wykonać na dwa sposoby:\n",
    "\n",
    "- <b>do przodu</b> zaczynamy ze znaną wartością $\\frac{dy_0}{dx} = \\frac{dx}{dx} = 1$. Następnie wyznaczamy wartość dla kolejnej instrukcji  $\\frac{dy_1}{dx} = \\frac{d_1}{dx} = 1$ i następnie:$\\frac{dy_{i+1}}{dy_i}$, aż otrzymamy pełny łańcuch.\n",
    "\n",
    "- <b>do tyłu</b> zaczynamy ze znaną wartością  $\\frac{dy}{dy_n} = \\frac{dy}{dy} = 1$. Następnie wyznaczamy wartości: $\\frac{dy}{dy_n}$, $\\frac{dy}{dy_{n-1}}$, ... $\\frac{dy}{dy_1}$, $\\frac{dy}{dx}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Zygote możemy przeskakiwać między liczbami dualnymi a pochodnymi (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De facto całe działanie biblioteki <tt>Zygote</tt> opiera się na dwóch kluczowych elementach: makrze <tt>@adjoint</tt> i funkcji <tt>pullback</tt>. \n",
    "\n",
    "<tt>pullback</tt> zwraca dwa wyniki, wartość oryginalnej funkcji $y = f(x)$ i wyrażenie $\\mathcal{B}(\\overline{y}) =  \\overline{y}  \\frac{dy}{dx}$, gdzie $\\overline{y} = \\frac{dl}{dy}$ jest parametrem, który musimy zdefiniować dla dowolnej funkcji $l$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Zygote\")\n",
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, back = Zygote.pullback(sin, π); # wyznacza pochodną;\n",
    "\n",
    "# y to oryginalna wartość funkcji (tutaj sin dla wartości pi);\n",
    "# back to wartość pochodnej razy y z kreska powyżej (patrz markdown wyżej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y   # sin(\\pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back(1)     # cosx, cos(π)= -1 \n",
    "\n",
    "# ptu odstawia 1 pod y z kreską, a więc otrzymujemy samą wartość pochodnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W szczególności funkcja <tt>gradient</tt> zakłada, że  $l = y = f(x)$ i $\\overline{y} = \\frac{dy}{dl} = 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(sin,π) == back(1) # czyli liczy po prostu wartość pierwszej pochodnej sin(x) w punkcie π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makro <tt>@adjoint</tt> pozwala nam w dowolny sposób modyfikować działanie mechanizmu wyznaczającego pochodne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote: @adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minus (generic function with 1 method)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, -1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(minus,2,3) # bo pochodna po a to 1, po b to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minus2 (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus2(a,b) = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@adjoint minus2(a,b) = minus2(a,b), c̄ -> (nothing, -b^2)        \n",
    "\n",
    "# modyfikacja tego jak liczona jest pochodna (czyli tutaj nie jest to prawdziwa pochodna);\n",
    "# natomiast to się może przydać gdy mamy np funkcje nierózniczkowalne a i tak chcemy wyznaczyć gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nothing, -9.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(minus2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Flux ponadto posiada zdefiniowane [podstawowe algorytmy optymalizacyjne](https://fluxml.ai/Flux.jl/stable/training/optimisers/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0001, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ADAM(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flux jest zdolny do kontrolowania całej procedury uczenia, nie musimy robić tego samodzielnie. Służy do tego funkcja <tt>train!</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: objective not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: objective not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[59]:1",
      " [2] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "Flux.train!(objective, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto jednak zaznaczyć, że pozwala ona na uczenie jedynie przez pojedynczą epokę. Aby móc kontynuować proces uczenia dalej musimy w odpowiedni sposób przystować dane z których korzystamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Vector{Float64}, Float64}}}(Base.Iterators.Repeated{Tuple{Vector{Float64}, Float64}}(([0.7178991031935313, 0.30440373377245156, 0.8983650194517316, 0.26365056795399977, 0.42919439162604867], 0.0)), 200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Base.Iterators: repeated\n",
    "dataset = repeated((x, y), 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo skorzystać z makra <tt>@epochs</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The macro `@epochs` will be removed from Flux 0.14.\n",
      "│ As an alternative, you can write a simple `for i in 1:epochs` loop.\n",
      "│   caller = eval at boot.jl:368 [inlined]\n",
      "└ @ Core .\\boot.jl:368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\Berenika\\.julia\\packages\\Flux\\kq9Et\\src\\optimise\\train.jl:185\n",
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\Berenika\\.julia\\packages\\Flux\\kq9Et\\src\\optimise\\train.jl:185\n"
     ]
    }
   ],
   "source": [
    "Flux.@epochs 2 println(\"hello\") #jak pętla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozwala ona też na definiowanie wywołań, które pozwolą nam kontrolować przebieg uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#19 (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb = () -> @show(loss(tX, tY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Berenika\\.julia\\environments\\v1.8\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Berenika\\.julia\\environments\\v1.8\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# import Pkg; Pkg.add(\"MLDatasets\")\n",
    "# import Pkg; Pkg.add(\"ImageCore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using MLDatasets: MNIST\n",
    "using ImageCore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od podstaw, wczytajmy i opracujmy zbiór danych na którym będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type DataType has no field download",
     "output_type": "error",
     "traceback": [
      "type DataType has no field download",
      "",
      "Stacktrace:",
      " [1] getproperty(#unused#::Type{MNIST}, s::Symbol)",
      "   @ MLDatasets C:\\Users\\Berenika\\.julia\\packages\\MLDatasets\\bg0uc\\src\\datasets\\vision\\mnist.jl:206",
      " [2] top-level scope",
      "   @ In[2]:1",
      " [3] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "ML.MNIST.download() # pobieranie - jeśli nie mamy pobranych, można kliknać y na pobranie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency MNIST.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: THE MNIST DATABASE of handwritten digits\n",
      "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
      "Website: http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "[LeCun et al., 1998a]\n",
      "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
      "    \"Gradient-based learning applied to document recognition.\"\n",
      "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
      "\n",
      "The files are available for download at the offical\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of MNIST aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"C:\\Users\\Berenika\\.julia\\datadeps\\MNIST\"?\n",
      "[y/n]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.traindata() is deprecated, use `MNIST(split=:train)[:]` instead.\n",
      "└ @ MLDatasets C:\\Users\\Berenika\\.julia\\packages\\MLDatasets\\bg0uc\\src\\datasets\\vision\\mnist.jl:187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"C:\\Users\\Berenika\\.julia\\datadeps\\MNIST\"?\n",
      "[y/n]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = MNIST.traindata();   # wczytywanie obrazów z ich etykietami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obejrzyjmy przykładowy obraz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST.convert2image(imgs)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "# Stack images into one large batch\n",
    "X = reshape(float.(imgs),size(imgs,1) * size(imgs,2),size(imgs,3))\n",
    "\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) \n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "accuracy(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I zacznijmy proces uczenia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymane wyniki możemy zapisywać korzystając z biblioteki [<tt>BSON</tt>](https://github.com/JuliaIO/BSON.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@save \"MNIST.bson\" m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i oczywiście wczytywać:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"MNIST.bson\" m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie powinniśmy przyjrzeć się wynikom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set accuracy\n",
    "timgs, tlabels = MNIST.testdata();\n",
    "\n",
    "#reshape data\n",
    "tX = reshape(float.(timgs),size(timgs,1) * size(timgs,2) ,size(timgs,3))\n",
    "\n",
    "# One-hot-encode the labels\n",
    "tY = onehotbatch(tlabels, 0:9) \n",
    "\n",
    "accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć neuronowa potrafi zoptymalizować jedynie wagi $\\theta$ funkcji liniowych wykorzystanych do budowy modelu. Pozostałe parametry (funkcje aktywacji, metoda regularyzacji, stopa uczenia, etc.) muszą być przyjęte z góry. Dobrać je można na kilka różnych sposobów:\n",
    "- wzorując się na literaturze\n",
    "- zgadując parametry\n",
    "- tworząc model [zdolny do nauczenia się optymalnej metody uczenia](https://arxiv.org/abs/2004.05439)\n",
    "- przeszukując odpowiednio przestrzeń hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowa praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Dokonaj strojenia hiperparametrów sieci omawianej na wykładzie. Sprobuj znaleźć taką, która zapewnia wyższą trafność predykcji <b>(5 punktów)</b>.\n",
    "2. W trakcie zajęć mówiliśmy o liczbach dualnych, czyli liczbach postaci $z = a + \\epsilon b$, gdzie $a,b \\in \\mathbb{R}$ a  $\\epsilon^2 = 0$. Dla dowolnego wielomanu  postaci $f(x) = a_0 + a_1x + a_2x^2 + \\dots + a_nx^n$ wartość takiego wielomianu dla liczby dualnej $z$ jest równa: $f(z) = f(a) + bf'(a)\\epsilon$. Pokaż, że tak jest naprawdę <b>(5 punktów)</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/> przeniesione komórki z góry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?> DelimitedFiles.readdlm # don't know why it's not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function 🐶()\n",
    "    println(\"Łapki only!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "🐶()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function 🦢(x)\n",
    "    x = x\n",
    "    print(\"łabądek musi isć tam zupełnie $x\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "🦢(\"nieprzygotowanyyyyy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "syntax of for loop: (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3]\n",
    "    println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i = [1, 2, 3]\n",
    "    println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2,3,4,5]; b = [10, 20, 30, 40]'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.*b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [2,3,4]' ; d = [10, 20, 30]\n",
    "println(c*d) # iloczyn skalarny\n",
    "println(c.*d)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
